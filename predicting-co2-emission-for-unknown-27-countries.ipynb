{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70983,"databundleVersionId":7794824,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samratabduljalil/predicting-co2-emission-for-unknown-27-countries?scriptVersionId=169373853\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<h1>predicting Co2 emission for unknown 27 countries .  </h1>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nTrain=pd.read_csv('/kaggle/input/ml-olympiad-co2-emissions-prediction-challenge/train.csv')\nTest= pd.read_csv('/kaggle/input/ml-olympiad-co2-emissions-prediction-challenge/test.csv')\nsample_submission= pd.read_csv('/kaggle/input/ml-olympiad-co2-emissions-prediction-challenge/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique = Train['Country Name'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train=Train.replace('..', .01020)\nTest=Test.replace('..', .01020) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainig and inferencing with LogisticRegression and ARIMA\nimport warnings\nimport tensorflow as tf\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense,Dropout\n\n\nk=0\nfor i in unique:\n    transposed_df=0\n    fg = Train[Train['Country Name'] == i].reset_index(drop=True)\n    columns_to_drop = ['Country Code', 'Country Name','Indicator']\n    fg = fg.drop(columns_to_drop, axis=1)\n    transposed_df = fg.transpose()\n    #print(fg)\n    #print('done for now')\n    Xtrain = transposed_df[[0,1, 2,3,4,9,10]].astype(float)\n    xt=Xtrain.values\n    Ytrain=transposed_df[11].astype(float) \n    yt=Ytrain.values\n    #logistic_regression = XGBRegressor()\n  \n\n   \n\n       # Compile model\n    \n  \n      # Reshape training data to fit the model input shape\n   \n\n      # Train the model\n    if k == 0:\n        k+=1\n        model = Sequential([\n              LSTM(64, return_sequences=True, input_shape=(Xtrain.shape[1], 1)),\n              Dropout(0.2),  # Adding dropout for regularization\n              LSTM(64, return_sequences=True),\n              Dropout(0.2),\n              LSTM(64),  # Last LSTM layer without return sequences\n              Dropout(0.2),\n              Dense(32, activation='relu'),  # Adding a dense layer for additional processing\n              Dense(1)  # Output layer\n              ])\n        model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n        Xtrain = xt.reshape((xt.shape[0], xt.shape[1], 1))\n        model.fit( Xtrain,  yt, epochs=22, batch_size=2)\n        model.save(\"/kaggle/working/my_lstm_model.h5\")\n    else:\n        loaded_model = tf.keras.models.load_model(\"/kaggle/working/my_lstm_model.h5\")\n        loaded_model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n        loaded_model.fit(Xtrain, yt, epochs=22, batch_size=2)\n        loaded_model.save(\"/kaggle/working/my_lstm_model.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Load this save model and run inference on 27 Unknown country and predict Co2 emission value.  then Fine tune this model for further improvement. Best of Luck </h1>","metadata":{}}]}