{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":70983,"databundleVersionId":7794824,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":1319.990749,"end_time":"2024-04-01T09:54:58.403483","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-01T09:32:58.412734","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Result could be different . because of some under fitting problem .if you run two time then you can understand the problem.public score beetween (.83 to 93)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nTrain=pd.read_csv('/kaggle/input/ml-olympiad-co2-emissions-prediction-challenge/train.csv')\nTest= pd.read_csv('/kaggle/input/ml-olympiad-co2-emissions-prediction-challenge/test.csv')\nsample_submission= pd.read_csv('/kaggle/input/ml-olympiad-co2-emissions-prediction-challenge/sample_submission.csv')","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:33:01.740924Z","iopub.status.busy":"2024-04-01T09:33:01.740548Z","iopub.status.idle":"2024-04-01T09:33:02.819060Z","shell.execute_reply":"2024-04-01T09:33:02.818020Z"},"papermill":{"duration":1.087148,"end_time":"2024-04-01T09:33:02.821839","exception":false,"start_time":"2024-04-01T09:33:01.734691","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace \"..\"with .100\nTrain=Train.replace('..', 0.102)  \nTest=Test.replace('..', 0.102)  ","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:33:02.831041Z","iopub.status.busy":"2024-04-01T09:33:02.830268Z","iopub.status.idle":"2024-04-01T09:33:02.855549Z","shell.execute_reply":"2024-04-01T09:33:02.854404Z"},"papermill":{"duration":0.032871,"end_time":"2024-04-01T09:33:02.858502","exception":false,"start_time":"2024-04-01T09:33:02.825631","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unique country for iteration\nunique = Train['Country Name'].unique()","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:33:02.867712Z","iopub.status.busy":"2024-04-01T09:33:02.867184Z","iopub.status.idle":"2024-04-01T09:33:02.879193Z","shell.execute_reply":"2024-04-01T09:33:02.878219Z"},"papermill":{"duration":0.019283,"end_time":"2024-04-01T09:33:02.881466","exception":false,"start_time":"2024-04-01T09:33:02.862183","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainig and inferencing with LogisticRegression and ARIMA\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.linear_model import LogisticRegression\nfrom statsmodels.tsa.arima.model import ARIMA\nimport numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nj=[]\nfor i in unique:\n    transposed_df=0\n    fg = Train[Train['Country Name'] == i].reset_index(drop=True)\n    columns_to_drop = ['Country Code', 'Country Name','Indicator']\n    fg = fg.drop(columns_to_drop, axis=1)\n    transposed_df = fg.transpose()\n    #print(fg)\n    #print('done for now')\n    Xtrain = transposed_df[[0,1, 2,3,4,5,6,7,8,9,10]]\n    Xtrain\n    Ytrain=transposed_df[11]\n    Ytrain\n    logistic_regression = LogisticRegression()\n    try:\n        logistic_regression.fit(Xtrain,Ytrain)\n        fgt = Test[Test['Country Name'] == i].reset_index(drop=True)\n        columns_to_drop = [ 'Country Name','Indicator']\n        fgt = fgt.drop(columns_to_drop, axis=1)\n        transposed_df = fgt.transpose()\n        #print(transposed_df)\n  \n        Xtest = transposed_df[[0,1, 2,3,4,5,6,7,8,9,10]]\n        forecast = logistic_regression.predict(Xtest.astype(float))\n        \n        model = ARIMA(Ytrain.astype(float), order=(0,1,3))  # Adjust order as needed\n        model_fit = model.fit()\n\n    \n        forecast2 = model_fit.forecast(steps=16)\n        \n        row_index = sample_submission[sample_submission.eq(i).any(axis=1)].index[0]\n\n\n        new_values = [i, forecast[0], forecast[1],forecast[2], forecast[3], forecast[4],forecast2[30]]\n        sample_submission.loc[row_index] = new_values\n    except:\n        j.append(i)\n    ","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:33:02.891063Z","iopub.status.busy":"2024-04-01T09:33:02.890032Z","iopub.status.idle":"2024-04-01T09:33:19.329066Z","shell.execute_reply":"2024-04-01T09:33:19.327738Z"},"papermill":{"duration":16.446886,"end_time":"2024-04-01T09:33:19.331990","exception":false,"start_time":"2024-04-01T09:33:02.885104","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainig and inferencing with LogisticRegression and ARIMA\nimport warnings\nimport tensorflow as tf\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense,Dropout\n\n\nk=0\nfor i in unique:\n    transposed_df=0\n    fg = Train[Train['Country Name'] == i].reset_index(drop=True)\n    columns_to_drop = ['Country Code', 'Country Name','Indicator']\n    fg = fg.drop(columns_to_drop, axis=1)\n    transposed_df = fg.transpose()\n    #print(fg)\n    #print('done for now')\n    Xtrain = transposed_df[[0,1, 2,3,4,9,10]].astype(float)\n    xt=Xtrain.values\n    Ytrain=transposed_df[11].astype(float) \n    yt=Ytrain.values\n    \n    if k == 0:\n        k+=1\n        model = Sequential([\n              LSTM(64, return_sequences=True, input_shape=(Xtrain.shape[1], 1)),\n              Dropout(0.2),  # Adding dropout for regularization\n              LSTM(64, return_sequences=True),\n              Dropout(0.2),\n              LSTM(64),  # Last LSTM layer without return sequences\n              Dropout(0.2),\n              Dense(32, activation='relu'),  # Adding a dense layer for additional processing\n              Dense(1)  # Output layer\n              ])\n        model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n        Xtrain = xt.reshape((xt.shape[0], xt.shape[1], 1))\n        model.fit( Xtrain,  yt, epochs=22, batch_size=4)\n        model.save(\"/kaggle/working/my_lstm_model.h5\")\n    else:\n        loaded_model = tf.keras.models.load_model(\"/kaggle/working/my_lstm_model.h5\")\n        loaded_model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n        loaded_model.fit(Xtrain, yt, epochs=22, batch_size=4)\n        loaded_model.save(\"/kaggle/working/my_lstm_model.h5\")","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:33:19.359470Z","iopub.status.busy":"2024-04-01T09:33:19.358772Z","iopub.status.idle":"2024-04-01T09:54:35.126720Z","shell.execute_reply":"2024-04-01T09:54:35.125806Z"},"papermill":{"duration":1275.784477,"end_time":"2024-04-01T09:54:35.129309","exception":false,"start_time":"2024-04-01T09:33:19.344832","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting and forecasting unknown Co2 Value\nfor i in j:\n    fg = Test[Test['Country Name'] == i].reset_index(drop=True)\n    columns_to_drop = ['Country Name','Indicator']\n    fg = fg.drop(columns_to_drop, axis=1)\n    transposed_df = fg.transpose()\n    #print(fg)\n    #print('done for now')\n    XTest = transposed_df[[0,1, 2,3,4,9,10]]\n    loaded_model = tf.keras.models.load_model(\"/kaggle/working/my_lstm_model.h5\")\n   \n    forecast = loaded_model.predict(XTest.astype(float))\n    df = pd.DataFrame(forecast)\n    model2 = ARIMA(df[0], order=(0,1,3))  # Adjust order as needed\n    model_fit = model2.fit()\n\n    \n    forecast2 = model_fit.forecast(steps=16)\n        \n    row_index = sample_submission[sample_submission.eq(i).any(axis=1)].index[0]\n\n\n    new_values = [i, forecast[0][0], forecast[1][0],forecast[2][0], forecast[3][0], forecast[4][0],forecast2[14]]\n    sample_submission.loc[row_index] = new_values\n","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:54:35.550241Z","iopub.status.busy":"2024-04-01T09:54:35.549650Z","iopub.status.idle":"2024-04-01T09:54:54.906949Z","shell.execute_reply":"2024-04-01T09:54:54.905791Z"},"papermill":{"duration":19.570993,"end_time":"2024-04-01T09:54:54.909773","exception":false,"start_time":"2024-04-01T09:54:35.338780","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" sample_submission.head(15)","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:54:55.337627Z","iopub.status.busy":"2024-04-01T09:54:55.336615Z","iopub.status.idle":"2024-04-01T09:54:55.359612Z","shell.execute_reply":"2024-04-01T09:54:55.358508Z"},"papermill":{"duration":0.240385,"end_time":"2024-04-01T09:54:55.362294","exception":false,"start_time":"2024-04-01T09:54:55.121909","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2024-04-01T09:54:55.793387Z","iopub.status.busy":"2024-04-01T09:54:55.793015Z","iopub.status.idle":"2024-04-01T09:54:55.804087Z","shell.execute_reply":"2024-04-01T09:54:55.803143Z"},"papermill":{"duration":0.229236,"end_time":"2024-04-01T09:54:55.806568","exception":false,"start_time":"2024-04-01T09:54:55.577332","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}